{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e498efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Acceder al archivo:\n",
    "\n",
    "def archivos(nombre_archivo):\n",
    "    \n",
    "    df = pd.read_csv(nombre_archivo, on_bad_lines='skip')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af300c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Exploración completa del Dataframe, incluyendo algunos for y algunos if/else:\n",
    "\n",
    "def exploracion(df):\n",
    "        print(f\"La forma:\")\n",
    "        print(f\"{df.shape}\\n\")\n",
    "        print('_'*80)\n",
    "        print(f\"Las columnas:\")\n",
    "        print(f\"{df.columns}\\n\")\n",
    "        print('_'*80)\n",
    "        print(f\"Los tipos de datos:\")\n",
    "        print(f\"{df.dtypes}\\n\")\n",
    "        print('_'*80)\n",
    "        print('Datos únicos por columna:')\n",
    "        display(df.nunique())\n",
    "        print('_'*80)\n",
    "        print(f\"Los nulos:\")\n",
    "        print(f\"{df.isnull().sum()}\\n\")\n",
    "        print('_'*80)\n",
    "\n",
    "        #PORCENTAJES NULOS\n",
    "        porcentajes_nulos = df.isnull().mean() * 100\n",
    "        cols_numericas = df.select_dtypes(include=['number']).columns\n",
    "        cols_categoricas = df.select_dtypes(include=['object', 'category']).columns\n",
    "        nulos_numericas = porcentajes_nulos[cols_numericas]\n",
    "        nulos_categoricas = porcentajes_nulos[cols_categoricas]\n",
    "        \n",
    "        if (porcentajes_nulos > 0).any():\n",
    "            if (nulos_numericas > 0).any():\n",
    "                print('Porcentajes de nulos en columnas numéricas:')\n",
    "                print(nulos_numericas.sort_values(ascending=False))\n",
    "            else:\n",
    "                print('No hay nulos en columnas numéricas.')\n",
    "                print('_'*80)\n",
    "            \n",
    "            if (nulos_categoricas > 0).any():\n",
    "                print('\\nPorcentajes de nulos en columnas categóricas:')\n",
    "                print(nulos_categoricas.sort_values(ascending=False))\n",
    "            else:\n",
    "                print('No hay nulos en columnas categóricas.')\n",
    "        else:\n",
    "            pass\n",
    "        print('_'*80)\n",
    "\n",
    "        #CONTEO SOLO PARA COLUMNAS CON NULOS\n",
    "        columnas_cat_con_nulos = [col for col in cols_categoricas if df[col].isnull().any()]\n",
    "        if columnas_cat_con_nulos:\n",
    "            print('Distribución de valores en columnas categóricas con nulos:')\n",
    "            for col in columnas_cat_con_nulos:\n",
    "                print(f\"\\nRevisando '{col}':\")\n",
    "                print(df[col].value_counts(dropna=False))\n",
    "            print('_'*80)\n",
    "\n",
    "        #DUPLICADOS\n",
    "        cantid_duplicados = df.duplicated().sum()\n",
    "        print(f'Cantidad de duplicados: {cantid_duplicados}')\n",
    "        if cantid_duplicados >0:\n",
    "            print('Primeros duplicados:')\n",
    "            display(df[df.duplicated()].head(3))\n",
    "        else:\n",
    "            print('No hay duplicados')\n",
    "        print('_'*80)\n",
    "\n",
    "        #DESCRIPCIONES\n",
    "        columnas_num = df.select_dtypes(include='number')\n",
    "        if not columnas_num.empty:\n",
    "            print('Descripción datos numéricos:')\n",
    "            display(columnas_num.describe().T)\n",
    "        else:\n",
    "            print('No hay datos de tipo numérico')\n",
    "        print('_'*80)\n",
    "        columnas_str = df.select_dtypes(include='object')\n",
    "        if not columnas_str.empty:\n",
    "            print('Descripción datos string (moda):')\n",
    "            display(columnas_str.describe().T)\n",
    "        else:\n",
    "            print('No hay datos de tipo string')\n",
    "        print('_'*80)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def usar_iterative_imputer(df, col, umbral=0.4):\n",
    "        \n",
    "        # Obtenemos la matriz de correlaciones absolutas\n",
    "        correlaciones = df.corr().abs()\n",
    "        # Eliminamos la autocorrelación (relación de una columna consigo misma, que siempre será 1)\n",
    "        correlaciones_col = correlaciones[col].drop(labels=[col])\n",
    "        # Extraemos el resultado de si hay correlaciones significantes comparando con el umbral, en una variable\n",
    "        correlaciones_significativas = correlaciones_col[correlaciones_col >= umbral]\n",
    "        # Con el 'not' nos devolverá True si hay al menos una correlación >= umbral\n",
    "        return not correlaciones_significativas.empty  \n",
    "\n",
    "\n",
    "# Gestión de nulos en columnas categóricas:\n",
    "\n",
    "def imputacion_nulos(df):\n",
    "    # Imputación de columnas categóricas:\n",
    "    columnas_categóricas_con_nulos = df[df.columns[df.isnull().any()]].select_dtypes(include = \"O\").columns\n",
    "    for col in columnas_categóricas_con_nulos:\n",
    "        nulos = df[col].isnull().sum()\n",
    "        total = len(df)\n",
    "        porcentaje_nulos = nulos / total\n",
    "\n",
    "        if porcentaje_nulos > 0.20:\n",
    "            # Si hay más del 20% de nulos; rellenar con \"Desconocido\"\n",
    "            df[col] = df[col].fillna(\"Desconocido\")\n",
    "            print(f\"{col} se va a imputar con Desconocido\")\n",
    "        else:\n",
    "            # Menos del 20% de nulos\n",
    "            valores = df[col].value_counts(dropna=True)\n",
    "            if len(valores) >= 2:\n",
    "                # Calcular diferencia porcentual entre los dos más frecuentes\n",
    "                primero = valores.iloc[0]\n",
    "                segundo = valores.iloc[1]\n",
    "                diferencia = (primero - segundo) / total\n",
    "\n",
    "                if diferencia > 0.20:\n",
    "                    # Si la diferencia entre los dos más comunes > 20% → usar moda\n",
    "                    moda = valores.idxmax() #es lo mismo que decirle la moda = df[col].mode[0]\n",
    "                    df[col] = df[col].fillna(moda)\n",
    "                    print(f\"{col} se va a imputar con la moda\")\n",
    "                else:\n",
    "                    # Si no → usar \"Desconocido\"\n",
    "                    df[col] = df[col].fillna(\"Desconocido\")\n",
    "                    print(f\"{col} se va a imputar con Desconocido\")\n",
    "            else:\n",
    "                moda = valores.idxmax() #es lo mismo que decirle la moda = df[col].mode[0]\n",
    "                df[col] = df[col].fillna(moda)\n",
    "                print(f\"{col} se va a imputar con la moda\")\n",
    "                \n",
    "    # Imputación de columnas numéricas:\n",
    "    columnas_numericas_con_nulos = df[df.columns[df.isnull().any()]].select_dtypes(include = \"number\").columns\n",
    "\n",
    "    # Sacamos el porcentaje de nulos por columna:\n",
    "    for col in columnas_numericas_con_nulos:\n",
    "        nulos = df[col].isnull().sum()\n",
    "        total = len(df)\n",
    "        porcentaje_nulos = nulos / total\n",
    "\n",
    "        # Si es mayor a 20, imputamos con técnicas avanzadas según si hay o no correlación entre las columnas\n",
    "        if porcentaje_nulos > 0.20:\n",
    "            if usar_iterative_imputer(df, col, umbral=0.3) == True:\n",
    "                imputer_iter = IterativeImputer(max_iter = 150, random_state = 42)\n",
    "                df[col] = imputer_iter.fit_transform(df[[col]]).ravel()  # para aplanar el array que nos devuelve\n",
    "                print(f\"{col} se va a imputar con IterativeImputer\")\n",
    "            \n",
    "            else:\n",
    "                imputer_knn = KNNImputer(n_neighbors=10)\n",
    "                df[col] = imputer_knn.fit_transform(df[[col]]).ravel()\n",
    "                print(f\"{col} se va a imputar con KNNImputer\")\n",
    "\n",
    "        # Si es menor de 20, imputamos con media o mediana según la diferencia entre ellas\n",
    "        else:\n",
    "            media = df[col].mean()\n",
    "            mediana = df[col].median()\n",
    "            diferencia = abs(media - mediana) / media\n",
    "            if diferencia < 0.05:\n",
    "                df[col] = df[col].fillna(df[col].mean())\n",
    "                print(f\"{col} se va a imputar con la media\")\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "                print(f\"{col} se va a imputar con la mediana\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creamos una función para realizar gráficos de las columnas numéricas:\n",
    "\n",
    "def graficos(df):\n",
    "   \n",
    "    # Visualización de columnas numéricas:\n",
    "    # Seleccionamos columnas numéricas\n",
    "    columnas_num = df.select_dtypes(include=['number']).columns\n",
    "    bins=30\n",
    "\n",
    "    # Iteramos por cada columna numérica y creamos un gráfico de histograma:\n",
    "    df.hist(bins=bins, figsize=(25, 25), edgecolor='black')\n",
    "    plt.grid(color='darkgray', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Visualización de columnas categóricas:\n",
    "    # Seleccionamos columnas categóricas\n",
    "    columnas_cat = df.select_dtypes(include=['O']).columns\n",
    "\n",
    "    # Creamos un subplot que se ajusta a la cantidad de columnas de cada df:\n",
    "    num_cols = len(columnas_cat)            #Cuenta la cantidad de columnas de la lista previa\n",
    "    cols = 2                                #Fijamos que el tamaño del subplot sea de 2 columnas\n",
    "    filas = (num_cols + cols - 1) // cols   #Calculamos las filas necesarias según la cant. de col. que hay y las fijadas al subplot - 1, para evitar que queden graficos fuera en caso de haya un núm. impar de columnas en la lista \n",
    "\n",
    "    fig, axes = plt.subplots(filas, cols, figsize=(cols * 6, filas * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Iteramos con enumerate para obtener el índice del subplot y la columna correspondiente:\n",
    "    for i, col in enumerate(columnas_cat):\n",
    "        conteos = df[col].value_counts()\n",
    "\n",
    "        #En caso de que la cantidad de valores de la columna sea mayor a 6, usar un gráfico de barras \n",
    "        if len(conteos) > 6:\n",
    "            # Gráfico de barras\n",
    "            conteos.plot(kind='bar', ax=axes[i], edgecolor='black')\n",
    "            axes[i].set_title(f'Distribución de {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Frecuencia')\n",
    "        \n",
    "        #Si es menor de 6, usar un gráfico de quesito para una mejor visualización\n",
    "        else:\n",
    "            # Gráfico de quesito\n",
    "            axes[i].pie(conteos, labels=conteos.index, autopct='%1.1f%%', edgecolor='black')\n",
    "            axes[i].set_title(f'Porcentajes de {col}')\n",
    "\n",
    "    #Ocultamos los subplots que puedan quedar vacíos por cant. de columnas impares:\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efa86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sqlalchemy import create_engine  \n",
    "import pymysql\n",
    "\n",
    "# Configuramos la base de datos\n",
    "host = '127.0.0.1'\n",
    "user = 'root'\n",
    "password = 'AlumnaAdalab'\n",
    "database = 'proyecto_3'\n",
    "\n",
    "# Función de extracción de datos\n",
    "def extraccion_datos(file_path):\n",
    "    print(f\"Extrayendo datos del archivo {file_path}...\")\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "# Función de limpieza\n",
    "def limpieza(df):\n",
    "    nuevas_columnas = {}\n",
    "    for col in df.columns:\n",
    "        nuevas_columnas[col] = col.lower().replace(\".\", \"\").replace(\"_\",\"\").strip()\n",
    "    \n",
    "    columnas_str = df.select_dtypes(include=['object']).columns\n",
    "    for col in columnas_str:\n",
    "        mask = df[col].notna()\n",
    "        df.loc[mask, col] = df.loc[mask, col].str.lower().str.replace(\",\", \".\").str.replace(\"_\", \"\").str.strip()\n",
    "    \n",
    "    #La máscara crea un filtro para omitir las filas en cada columna que tenga valores nulos.\n",
    "    #df.loc aplica los cambios solo a los valores no nulos.\n",
    "\n",
    "    df.rename(columns = nuevas_columnas, inplace = True)\n",
    "\n",
    "    return df \n",
    "\n",
    "# Funciones imputación de nulos\n",
    "\n",
    "# Gestión de nulos en columnas categóricas:\n",
    "def nulos_categoricas(df):\n",
    "    columnas_categóricas_con_nulos = df[df.columns[df.isnull().any()]].select_dtypes(include = \"O\").columns\n",
    "    for col in columnas_categóricas_con_nulos:\n",
    "        nulos = df[col].isnull().sum()\n",
    "        total = len(df)\n",
    "        porcentaje_nulos = nulos / total\n",
    "\n",
    "        if porcentaje_nulos > 0.20:\n",
    "            # Si hay más del 20% de nulos; rellenar con \"Desconocido\"\n",
    "            df[col] = df[col].fillna(\"Desconocido\")\n",
    "            print(f\"{col} se va a imputar con Desconocido\")\n",
    "        else:\n",
    "            # Menos del 20% de nulos\n",
    "            valores = df[col].value_counts(dropna=True)\n",
    "            if len(valores) >= 2:\n",
    "                # Calcular diferencia porcentual entre los dos más frecuentes\n",
    "                primero = valores.iloc[0]\n",
    "                segundo = valores.iloc[1]\n",
    "                diferencia = (primero - segundo) / total\n",
    "\n",
    "                if diferencia > 0.20:\n",
    "                    # Si la diferencia entre los dos más comunes > 20% → usar moda\n",
    "                    moda = valores.idxmax() #es lo mismo que decirle la moda = df[col].mode[0]\n",
    "                    df[col] = df[col].fillna(moda)\n",
    "                    print(f\"{col} se va a imputar con la moda\")\n",
    "                else:\n",
    "                    # Si no → usar \"Desconocido\"\n",
    "                    df[col] = df[col].fillna(\"Desconocido\")\n",
    "                    print(f\"{col} se va a imputar con Desconocido\")\n",
    "            else:\n",
    "                moda = valores.idxmax() #es lo mismo que decirle la moda = df[col].mode[0]\n",
    "                df[col] = df[col].fillna(moda)\n",
    "                print(f\"{col} se va a imputar con la moda\")\n",
    "    return df\n",
    "\n",
    "# Gestión de nulos en columnas numéricas:\n",
    "\n",
    "# Creamos 1o una función que usaremos dentro de la otra función\n",
    "# Esta función valorará si hay suficiente correlación entre las columnas como para usar el IterativeImputer\n",
    "def usar_iterative_imputer(df, col, umbral=0.4):\n",
    "        # Obtenemos la matriz de correlaciones absolutas\n",
    "        correlaciones = df.corr().abs()\n",
    "        # Eliminamos la autocorrelación (relación de una columna consigo misma, que siempre será 1)\n",
    "        correlaciones_col = correlaciones[col].drop(labels=[col])\n",
    "        # Extraemos el resultado de si hay correlaciones significantes comparando con el umbral, en una variable\n",
    "        correlaciones_significativas = correlaciones_col[correlaciones_col >= umbral]\n",
    "        # Con el 'not' nos devolverá True si hay al menos una correlación >= umbral\n",
    "        return not correlaciones_significativas.empty  \n",
    "\n",
    "# Creamos la función para imputar los nulos numéricos según parámetros aprendidos:\n",
    "def nulos_numericas(df):\n",
    "    columnas_numericas_con_nulos = df[df.columns[df.isnull().any()]].select_dtypes(include = \"number\").columns\n",
    "\n",
    "    # Sacamos el porcentaje de nulos por columna:\n",
    "    for col in columnas_numericas_con_nulos:\n",
    "        nulos = df[col].isnull().sum()\n",
    "        total = len(df)\n",
    "        porcentaje_nulos = nulos / total\n",
    "\n",
    "        # Si es mayor a 20, imputamos con técnicas avanzadas según si hay o no correlación entre las columnas\n",
    "        if porcentaje_nulos > 0.20:\n",
    "            if usar_iterative_imputer(df, col, umbral=0.3) == True:\n",
    "                imputer_iter = IterativeImputer(max_iter = 150, random_state = 42)\n",
    "                df[col] = imputer_iter.fit_transform(df[[col]]).ravel()  # para aplanar el array que nos devuelve\n",
    "                print(f\"{col} se va a imputar con IterativeImputer\")\n",
    "            \n",
    "            else:\n",
    "                imputer_knn = KNNImputer(n_neighbors=10)\n",
    "                df[col] = imputer_knn.fit_transform(df[[col]]).ravel()\n",
    "                print(f\"{col} se va a imputar con KNNImputer\")\n",
    "\n",
    "        # Si es menor de 20, imputamos con media o mediana según la diferencia entre ellas\n",
    "        else:\n",
    "            media = df[col].mean()\n",
    "            mediana = df[col].median()\n",
    "            diferencia = abs(media - mediana) / media\n",
    "            if diferencia < 0.05:\n",
    "                df[col] = df[col].fillna(df[col].mean())\n",
    "                print(f\"{col} se va a imputar con la media\")\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "                print(f\"{col} se va a imputar con la mediana\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Funciones de conexión y de carga de datos\n",
    "def conexion(database):\n",
    "    # Conectar a MySQL usando pymysql\n",
    "    connection = pymysql.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "\n",
    "    # Crear un cursor\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Cerrar la conexión\n",
    "    connection.close()\n",
    "\n",
    "def carga_datos(tabla, df_datos):\n",
    "    print(f\"Cargando datos en la tabla {tabla}...\")\n",
    "\n",
    "    # Crear conexión a MySQL usando SQLAlchemy\n",
    "    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}/{database}')\n",
    "\n",
    "    # Insertar datos desde el DataFrame en MySQL\n",
    "    df_datos = pd.DataFrame(df_datos).to_sql(tabla, con=engine, if_exists='append', index=False)\n",
    "    print(f\"Datos insertados en la tabla {tabla} exitosamente.\")\n",
    "\n",
    "# Función de ETL completa\n",
    "def proceso_etl(tabla, csv):\n",
    "\n",
    "    # Extraer, transformar y cargar los datos del csv\n",
    "    df = extraccion_datos(csv)\n",
    "    df_exploracion = exploracion(df)\n",
    "    df_modificado = limpieza(df)\n",
    "    df_imputado_cat = nulos_categoricas(df_modificado)\n",
    "    df_imputado_num = nulos_numericas(df_imputado_cat)\n",
    "    carga_datos(tabla, df_imputado_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c93017f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo datos del archivo HR RAW DATA nulos imputados 04-06.csv...\n",
      "   age attrition businesstravel  distancefromhome  education gender  \\\n",
      "0   51        no        Unknown                 6          3      m   \n",
      "1   52        no        Unknown                 1          4      m   \n",
      "2   42        no  travel_rarely                 4          2      m   \n",
      "3   47        no  travel_rarely                 2          4      f   \n",
      "4   46        no        Unknown                 3          3      f   \n",
      "\n",
      "   jobinvolvement  joblevel              jobrole  jobsatisfaction  ...  \\\n",
      "0               3         5   research director                 3  ...   \n",
      "1               2         5             manager                 3  ...   \n",
      "2               3         5             manager                 4  ...   \n",
      "3               3         4   research director                 3  ...   \n",
      "4               4         4     sales executive                 1  ...   \n",
      "\n",
      "  standardhours  stockoptionlevel  trainingtimeslastyear worklifebalance  \\\n",
      "0     full_time                 0                      5               3   \n",
      "1     full_time                 1                      5               3   \n",
      "2     full_time                 0                      3               3   \n",
      "3     full_time                 2                      2               3   \n",
      "4     full_time                 1                      5               3   \n",
      "\n",
      "   yearsatcompany  yearssincelastpromotion yearswithcurrmanager  remotework  \\\n",
      "0              20                       15                   15         yes   \n",
      "1              33                       11                    9         yes   \n",
      "2              22                       11                   15         yes   \n",
      "3              20                        5                    6          no   \n",
      "4              19                        2                    8          no   \n",
      "\n",
      "               department  environmentsatisfaction  \n",
      "0  research & development                        1  \n",
      "1                  unknow                        3  \n",
      "2  research & development                        3  \n",
      "3  research & development                        1  \n",
      "4                   sales                        1  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "Cargando datos en la tabla hr_raw_data...\n",
      "Datos insertados en la tabla hr_raw_data exitosamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ejecutar el proceso ETL completo\n",
    "proceso_etl(\"hr_raw_data\", \"HR RAW DATA nulos imputados 04-06.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
